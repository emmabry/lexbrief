{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419009\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the summarisation pipeline with the BART large CNN model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"dennlinger/eur-lex-sum\", 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419009\n"
     ]
    }
   ],
   "source": [
    "example_text = dataset['train'][0]['reference']\n",
    "print(len(example_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 66421\n"
     ]
    }
   ],
   "source": [
    "# Length is way too long for the summariser (419009 chars), so need to try other strategies\n",
    "words = example_text.split()\n",
    "print(f\"Total words: {len(words)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 130, but your input_length is only 45. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined summary:\n",
      " Regulation (EU) 2017/1129 lays down requirements to be complied with when drawing up prospectuses. The content and the format of a prospectus depend on a variety of factors, such as the type of issuer, type of security and type of issuance. The prospectus should contain a working capital statement as well as a statement of capitalisation and indebtedness of the issuer of the underlying shares. Derivative securities entail particular risks for investors. A high level of investor protection should be ensured, the EU says. It adds that certain types of securities that are not covered by the Annexes to this Regulation will be offered to the public. ‘Third country market’ means a third country market which has been deemed equivalent to a regulated market in accordance with the requirements set out in third and fourth subparagraphs of Article 25(4) of Directive 2014/65/EU of the European Parliament and of the Council (3) ‘profit estimate’ is a profit forecast for a financial period which has ...\n"
     ]
    }
   ],
   "source": [
    "# Split into 800-word chunks\n",
    "def chunk_text(words, max_words=800):\n",
    "    for i in range(0, len(words), max_words):\n",
    "        yield ' '.join(words[i:i + max_words])\n",
    "\n",
    "chunks = list(chunk_text(words))\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "\n",
    "# Summarise each chunk\n",
    "summaries = []\n",
    "for chunk in chunks:\n",
    "    summary = summarizer(\n",
    "        chunk,\n",
    "        max_length=130,\n",
    "        min_length=30,\n",
    "        do_sample=False\n",
    "    )\n",
    "    summaries.append(summary[0]['summary_text'])\n",
    "\n",
    "# Combine\n",
    "final_summary = \" \".join(summaries)\n",
    "print(\"Combined summary:\\n\", final_summary[:1000], \"...\")  # print first 1000 chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 F1: 0.4100086281276963\n",
      "ROUGE-2 F1: 0.13637148282409806\n",
      "ROUGE-L F1: 0.16496980155306298\n"
     ]
    }
   ],
   "source": [
    "# Testing summary against original summary in data using ROUGE\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "dataset_summary = dataset['train'][0]['summary']\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(dataset_summary, final_summary)\n",
    "\n",
    "print(\"ROUGE-1 F1:\", scores['rouge1'].fmeasure)\n",
    "print(\"ROUGE-2 F1:\", scores['rouge2'].fmeasure)\n",
    "print(\"ROUGE-L F1:\", scores['rougeL'].fmeasure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a chunked summarisation and naive combination, these results are expected as we lose some coherence.\n",
    "For fine tuned models on domain specific data, should aim for:\n",
    "- ROUGE-1 F1 0.5 to 0.7 or higher\n",
    "- ROUGE-2 F1 0.3 to 0.5\n",
    "- ROUGE-L F1 usually close to ROUGE-1, around 0.5+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
